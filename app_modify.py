import os
from dotenv import load_dotenv
import streamlit as st
from langdetect import detect
import unicodedata

from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI
from PyPDF2 import PdfReader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.prompts import PromptTemplate
from langchain.chains.question_answering import load_qa_chain

load_dotenv()

# Load GOOGLE_API_KEY from environment variables
GOOGLE_API_KEY = os.getenv("GOOGLE_API_KEY")

# Raise an error if the key is not found
if not GOOGLE_API_KEY:
    raise ValueError("GOOGLE_API_KEY not found in environment variables.")

# Templates for the QA chain (in both languages)
template_en = """You are a chatbot having a conversation with a user based on the context.

Given the following extracted parts of a long document and a question, create a final answer. If you do not have the context, please do not give a wrong answer.

Context: \n {context}\n

Question: \n {question}\n
Answer:"""

template_hi = """‡§Ü‡§™ ‡§è‡§ï ‡§ö‡•à‡§ü‡§¨‡•â‡§ü ‡§π‡•à‡§Ç ‡§ú‡•ã ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§∏‡•á ‡§¨‡§æ‡§§‡§ö‡•Ä‡§§ ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç‡•§

‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§≤‡§Ç‡§¨‡•á ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•á ‡§®‡§ø‡§ï‡§æ‡§≤‡•á ‡§ó‡§è ‡§≠‡§æ‡§ó‡•ã‡§Ç ‡§î‡§∞ ‡§è‡§ï ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞ ‡§è‡§ï ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§â‡§§‡•ç‡§§‡§∞ ‡§¨‡§®‡§æ‡§è‡§Ç‡•§ ‡§Ø‡§¶‡§ø ‡§Ü‡§™‡§ï‡•á ‡§™‡§æ‡§∏ ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à, ‡§§‡•ã ‡§ï‡•É‡§™‡§Ø‡§æ ‡§ó‡§≤‡§§ ‡§â‡§§‡•ç‡§§‡§∞ ‡§® ‡§¶‡•á‡§Ç‡•§

‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠: \n {context}\n

‡§™‡•ç‡§∞‡§∂‡•ç‡§®: \n {question}\n
‡§â‡§§‡•ç‡§§‡§∞:"""

# Function to detect language
def detect_language(text):
    try:
        return detect(text)
    except:
        return 'en'  # Default to English if detection fails

# Function to read PDF and extract text
def get_pdf_text(pdf_docs):
    text = ""
    for pdf in pdf_docs:
        try:
            pdf_reader = PdfReader(pdf)
            for page in pdf_reader.pages:
                text += page.extract_text()
        except Exception as e:
            st.error(f"Error processing PDF: {str(e)}")
    return text

# Function to split text into chunks
def get_text_chunks(text, chunk_size=4000, chunk_overlap=200):
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=chunk_overlap,
        separators=["\n\n", "\n", " ", ""]
    )
    chunks = text_splitter.split_text(text)
    return chunks

# Function to create a vector store from text chunks
def get_vector_store(text_chunks):
    if not text_chunks:
        st.error("No text could be extracted from the PDF. \nPlease check if the file is valid and not empty.")
        return None
    
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=GOOGLE_API_KEY)
    vector_store = FAISS.from_texts(text_chunks, embedding=embeddings)
    vector_store.save_local("faiss_index")
    return vector_store

# Function to create a conversational chain
def get_conversational_chain(lang):
    model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.5)
    prompt = PromptTemplate(input_variables=["question", "context"], template=template_en if lang == 'en' else template_hi)
    chain = load_qa_chain(model, chain_type="stuff", prompt=prompt)
    return chain

# Function to generate summary for a chunk of text
def generate_chunk_summary(text, lang):
    model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.5)
    
    summary_prompt_en = """
    You are an AI assistant tasked with summarizing documents. Given the following text from a part of a document, 
    create a concise summary that captures the main points and key information. The summary should be informative 
    and focus on the most important aspects.

    Text:
    {text}

    Please provide a summary in about 2-3 sentences.
    """
    
    summary_prompt_hi = """
    ‡§Ü‡§™ ‡§è‡§ï AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º‡•ã‡§Ç ‡§ï‡§æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§∏‡•å‡§Ç‡§™‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•á ‡§è‡§ï ‡§≠‡§æ‡§ó ‡§∏‡•á ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§™‡§æ‡§† ‡§¶‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à, 
    ‡§è‡§ï ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§¨‡§®‡§æ‡§è‡§Ç ‡§ú‡•ã ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§î‡§∞ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§ï‡•à‡§™‡•ç‡§ö‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§∏‡•Ç‡§ö‡§®‡§æ‡§§‡•ç‡§Æ‡§ï ‡§π‡•ã‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è 
    ‡§î‡§∞ ‡§∏‡§¨‡§∏‡•á ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§™‡§π‡§≤‡•Å‡§ì‡§Ç ‡§™‡§∞ ‡§ß‡•ç‡§Ø‡§æ‡§® ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞‡§ø‡§§ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è‡•§

    ‡§™‡§æ‡§†:
    {text}

    ‡§ï‡•É‡§™‡§Ø‡§æ ‡§≤‡§ó‡§≠‡§ó 2-3 ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§
    """
    
    prompt = summary_prompt_en if lang == 'en' else summary_prompt_hi
    response = model.invoke(prompt.format(text=text))
    return response.content

# Function to generate summary for the entire document
def generate_full_summary(text, lang):
    chunks = get_text_chunks(text, chunk_size=4000, chunk_overlap=200)
    chunk_summaries = []
    
    for i, chunk in enumerate(chunks):
        with st.spinner(f"Summarizing part {i+1}/{len(chunks)}..." if lang == 'en' else f"‡§≠‡§æ‡§ó {i+1}/{len(chunks)} ‡§ï‡§æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§¨‡§®‡§æ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç..."):
            chunk_summary = generate_chunk_summary(chunk, lang)
            chunk_summaries.append(chunk_summary)
    
    # Combine chunk summaries
    combined_summary = " ".join(chunk_summaries)
    
    # Generate final summary
    model = ChatGoogleGenerativeAI(model="gemini-pro", temperature=0.5)
    final_summary_prompt_en = """
    You are an AI assistant tasked with creating a comprehensive summary. Given the following combined summaries 
    of different parts of a document, create a coherent and concise final summary that captures the main points 
    and key information of the entire document.

    Combined Summaries:
    {combined_summary}

    Please provide a final summary in about 5-7 sentences, ensuring all major points are covered.
    Finally , strictly ensure to provide the summary in a clean formatted strucuture , headers ,sub-headers, bullet points and even symbols , icons to express beautifully.
    """
    
    final_summary_prompt_hi = """
    ‡§Ü‡§™ ‡§è‡§ï AI ‡§∏‡§π‡§æ‡§Ø‡§ï ‡§π‡•à‡§Ç ‡§ú‡§ø‡§∏‡•á ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡§æ ‡§ï‡§æ‡§Æ ‡§∏‡•å‡§Ç‡§™‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•á ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§≠‡§æ‡§ó‡•ã‡§Ç ‡§ï‡•á ‡§®‡§ø‡§Æ‡•ç‡§®‡§≤‡§ø‡§ñ‡§ø‡§§ ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂‡•ã‡§Ç ‡§ï‡•á ‡§Ü‡§ß‡§æ‡§∞ ‡§™‡§∞, 
    ‡§è‡§ï ‡§∏‡•Å‡§∏‡§Ç‡§ó‡§§ ‡§î‡§∞ ‡§∏‡§Ç‡§ï‡•ç‡§∑‡§ø‡§™‡•ç‡§§ ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§¨‡§®‡§æ‡§è‡§Ç ‡§ú‡•ã ‡§™‡•Ç‡§∞‡•á ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•á ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§¨‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§î‡§∞ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä ‡§ï‡•ã ‡§ï‡•à‡§™‡•ç‡§ö‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§

    ‡§∏‡§Ç‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂:
    {combined_summary}

    ‡§ï‡•É‡§™‡§Ø‡§æ ‡§≤‡§ó‡§≠‡§ó 5-7 ‡§µ‡§æ‡§ï‡•ç‡§Ø‡•ã‡§Ç ‡§Æ‡•á‡§Ç ‡§è‡§ï ‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç, ‡§Ø‡§π ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•Å‡§è ‡§ï‡§ø ‡§∏‡§≠‡•Ä ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§¨‡§ø‡§Ç‡§¶‡•Å‡§ì‡§Ç ‡§ï‡•ã ‡§ï‡§µ‡§∞ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§
    ‡§Ö‡§Ç‡§§ ‡§Æ‡•á‡§Ç, ‡§∏‡•Å‡§®‡§ø‡§∂‡•ç‡§ö‡§ø‡§§ ‡§ï‡§∞‡•á‡§Ç ‡§ï‡§ø ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂ ‡§ï‡•ã ‡§è‡§ï ‡§∏‡§æ‡§´-‡§∏‡•Å‡§•‡§∞‡•á ‡§î‡§∞ ‡§∏‡§Ç‡§∞‡§ö‡§ø‡§§ ‡§§‡§∞‡•Ä‡§ï‡•á ‡§∏‡•á ‡§™‡•ç‡§∞‡§∏‡•ç‡§§‡•Å‡§§ ‡§ï‡§∞‡•á‡§Ç, ‡§π‡•á‡§°‡§∞, ‡§∏‡§¨-‡§π‡•á‡§°‡§∞, ‡§¨‡•Å‡§≤‡•á‡§ü ‡§™‡•â‡§á‡§Ç‡§ü‡•ç‡§∏ ‡§î‡§∞ ‡§Ø‡§π‡§æ‡§Ç ‡§§‡§ï ‡§ï‡§ø ‡§™‡•ç‡§∞‡§§‡•Ä‡§ï‡•ã‡§Ç, ‡§Ü‡§á‡§ï‡§®‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§ï‡•á ‡§∏‡•Å‡§Ç‡§¶‡§∞‡§§‡§æ ‡§∏‡•á ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§ ‡§ï‡§∞‡•á‡§Ç‡•§
    """
    
    prompt = final_summary_prompt_en if lang == 'en' else final_summary_prompt_hi
    response = model.invoke(prompt.format(combined_summary=combined_summary))
    return response.content

# Function to process user input and display the response
def user_input(user_question, lang):
    embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001", google_api_key=GOOGLE_API_KEY)
    new_db = FAISS.load_local("faiss_index", embeddings, allow_dangerous_deserialization=True)
    docs = new_db.similarity_search(user_question)
    chain = get_conversational_chain(lang)
    response = chain({"input_documents": docs, "question": user_question})
    st.write("*Answer: *" if lang == 'en' else "*‡§â‡§§‡•ç‡§§‡§∞: *", response["output_text"])

# Streamlit app setup
st.set_page_config(
    page_title="Document Summarizer",
    page_icon=":books:",
    layout="wide",
    initial_sidebar_state="auto"
)

def main():
    st.header("üñáÔ∏èüñáÔ∏è DocDigest üìëüìú")

    # File uploader in the main content area
    pdf_docs = st.file_uploader("Upload your Document(.pdf)", accept_multiple_files=False, type=['pdf'])

    if pdf_docs:
        if st.button("Generate Document Summary"):
            with st.spinner("Processing..."):
                raw_text = get_pdf_text([pdf_docs])  # Pass as a list
                if not raw_text.strip():
                    st.error("No text could be extracted from the PDF. Please check if the file is valid and not empty.")
                    return

                lang = detect_language(raw_text)
                text_chunks = get_text_chunks(raw_text)
                vector_store = get_vector_store(text_chunks)
                
                if vector_store is None:
                    return

                # Generate and display summary
               summary = generate_full_summary(raw_text, lang)
                st.session_state['summary'] = summary
                st.session_state['pdf_processed'] = True
                st.session_state['lang'] = lang

                st.subheader("Document Summary")
                st.write(summary)
                st.divider()

                st.success("Summary Generated Successfully. ")

    # Display summary if available
    if 'summary' in st.session_state:
        st.subheader("Document Summary ")
        st.write(st.session_state['summary'])
        st.divider()

    # Question input
    user_question = st.text_input("Ask your question about the document ")

    if user_question and st.session_state.get('pdf_processed', False):
        user_input(user_question, st.session_state['lang'])
    elif user_question:
        st.warning("Please process a PDF before asking questions. ")

if __name__ == "__main__":
    main()
